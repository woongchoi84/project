{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 붓꽃의 품종 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서플로 버전: 2.0.0-rc1\n",
      "즉시 실행: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"텐서플로 버전: {}\".format(tf.__version__))\n",
    "print(\"즉시 실행: {}\".format(tf.executing_eagerly()))\n",
    "np.set_printoptions(precision=3, linewidth=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 측정된 꽃받침과 꽃잎의 길이와 폭을 토대로 붓꽃을 분류하는 모델을 통해 경사하강법(GD) 학습\n",
    "* Iris setosa\n",
    "* Iris virginica\n",
    "* Iris versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![꽃](https://www.tensorflow.org/images/iris_three_species.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋이 복사된 위치: /home/woong/.keras/datasets/iris_training.csv\n",
      "120,4,setosa,versicolor,virginica\n",
      "6.4,2.8,5.6,2.2,2\n",
      "5.0,2.3,3.3,1.0,1\n",
      "4.9,2.5,4.5,1.7,2\n",
      "4.9,3.1,1.5,0.1,0\n",
      "30,4,setosa,versicolor,virginica\n",
      "5.9,3.0,4.2,1.5,1\n",
      "6.9,3.1,5.4,2.1,2\n",
      "5.1,3.3,1.7,0.5,0\n",
      "6.0,3.4,4.5,1.6,1\n"
     ]
    }
   ],
   "source": [
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "test__dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url), origin=train_dataset_url)\n",
    "test__dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(test__dataset_url), origin=test__dataset_url)\n",
    "\n",
    "print(\"데이터셋이 복사된 위치: {}\".format(train_dataset_fp))\n",
    "!head -n5 {train_dataset_fp}\n",
    "!head -n5 {test__dataset_fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "레이블: species\n"
     ]
    }
   ],
   "source": [
    "# column_name = ['꽃잎 길이', '꽃잎 너비', '꽃받침 길이', '꽃받침 너비', '종']\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "# species = 0: Iris setosa, 1: Iris versicolor, 2: Iris virginica\n",
    "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"특성: {}\".format(feature_names))\n",
    "print(\"레이블: {}\".format(label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:521: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    shuffle=False,\n",
    "    num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "plt.scatter(features['petal_length'], features['sepal_length'], c=labels, cmap='viridis')\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Sepal length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "  \"\"\"특성들을 단일 배열로 묶습니다.\"\"\"\n",
    "# tf.stack: Stacks a list of rank-R tensors into one rank-(R+1) tensor.\n",
    "  features = tf.stack(list(features.values()), axis=1)\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function pack_features_vector at 0x7fe6aa67f950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function pack_features_vector at 0x7fe6aa67f950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 4), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6.4 2.8 5.6 2.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.7 3.8 1.7 0.3]], shape=(5, 4), dtype=float32) tf.Tensor([2 1 2 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "print(features[:5], labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           6.4          2.8           5.6          2.2\n",
       "1           5.0          2.3           3.3          1.0\n",
       "2           4.9          2.5           4.5          1.7\n",
       "3           4.9          3.1           1.5          0.1\n",
       "4           5.7          3.8           1.7          0.3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas.read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
    "pdFeature = pd.read_csv(train_dataset_fp, sep=',', skiprows=1, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "\n",
    "# pandas.DataFrame.pop : Return item and drop from frame. Raise KeyError if not found.\n",
    "pdLabel = pdFeature.pop('species')\n",
    "\n",
    "# pandas.DataFrame.head : Return the first n rows.\n",
    "pdFeature.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.data.Dataset.from_tensor_slices: Creates a Dataset whose elements are slices of the given tensors..\n",
    "pdDataset = tf.data.Dataset.from_tensor_slices((pdFeature.values, pdLabel.values))\n",
    "pdFeature.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 0, Features: [6.4 2.8 5.6 2.2], Species: 2\n",
      "Row: 1, Features: [5.  2.3 3.3 1. ], Species: 1\n",
      "Row: 2, Features: [4.9 2.5 4.5 1.7], Species: 2\n",
      "Row: 3, Features: [4.9 3.1 1.5 0.1], Species: 0\n",
      "Row: 4, Features: [5.7 3.8 1.7 0.3], Species: 0\n"
     ]
    }
   ],
   "source": [
    "for row, data in enumerate(pdDataset.take(5)):\n",
    "    print ('Row: {}, Features: {}, Species: {}'.format(row, data[0], data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tensorflow.org/images/custom_estimators/full_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.Sequential: Linear stack of layers.\n",
    "# Please check the configuration of each layer (press 'Shift+Tab' in xx.Dense(here!))\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # Weight:  4-inputs * 10-dense =  40,  Bias: 10, Total:  50\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),                    # Weight: 10-inputs * 10-dense = 100,  Bias: 10, Total: 110\n",
    "  tf.keras.layers.Dense(3)                                             # Weight: 10-inputs *  3-dense =  30,  Bias:  3, Total:  33\n",
    "])\n",
    "model.summary()\n",
    "#help(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 (Training) 전 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (32, 4)\n",
      "Layer 0: Weight(4, 10) Bias(10,) Activation(None, 10)\n",
      "Layer 1: Weight(10, 10) Bias(10,) Activation(None, 10)\n",
      "Layer 2: Weight(10, 3) Bias(3,) Activation(None, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Input Shape: {}'.format(features.shape))\n",
    "for i in range(len(model.layers)):\n",
    "    print('Layer {}: Weight{} Bias{} Activation{}'.format(i, model.layers[i].weights[0].shape, model.layers[i].bias.shape, model.layers[i].output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 1st Features:\n",
      " [6.4 2.8 5.6 2.2]\n",
      "\n",
      ">> Weights (Input-Layer1):\n",
      " [[ 0.607 -0.594 -0.64  -0.342  0.445 -0.394  0.119 -0.052 -0.313 -0.001]\n",
      " [-0.469 -0.542 -0.473  0.352 -0.094 -0.193  0.093 -0.132  0.386  0.425]\n",
      " [-0.461  0.495  0.497  0.14  -0.496 -0.285  0.257  0.144  0.053  0.502]\n",
      " [ 0.287 -0.192  0.064  0.391  0.491  0.566  0.268  0.631 -0.58   0.046]]\n",
      "\n",
      ">> Biases   (Input-Layer1):\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      ">> Layer1 MatMul[0,0]: 0.6221869\n",
      "\n",
      ">> Layer1 MatMul: \n",
      " [[ 0.622 -2.973 -2.493  0.438  0.883 -3.411  3.047  1.493 -1.901  4.096]\n",
      " [ 0.723 -2.778 -2.581 -0.049  0.86  -2.787  1.923  0.543 -1.081  2.675]\n",
      " [ 0.216 -2.368 -1.971  0.497  0.545 -2.732  2.425  1.136 -1.316  3.395]\n",
      " [ 0.858 -3.871 -3.848 -0.336  1.191 -2.898  1.282 -0.385 -0.314  2.071]\n",
      " [ 0.981 -4.666 -4.579 -0.257  1.48  -3.292  1.547 -0.364 -0.399  2.477]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('>> 1st Features:\\n %s\\n'%(features[0].numpy()))\n",
    "print('>> Weights (Input-Layer1):\\n %s\\n'%(model.layers[0].weights[0].numpy()))\n",
    "print('>> Biases   (Input-Layer1):\\n %s\\n'%(model.layers[0].bias.numpy()))\n",
    "print('>> Layer1 MatMul[0,0]: %s\\n'%(np.sum(features[0]*model.layers[0].weights[0][:,0])))\n",
    "print('>> Layer1 MatMul: \\n %s\\n'%(tf.matmul(features, model.layers[0].weights[0]).numpy()[:5]))\n",
    "\n",
    "actLayer0 = tf.nn.relu(tf.matmul(features,  model.layers[0].weights[0]) + tf.ones([batch_size, 1]) * model.layers[0].bias)\n",
    "actLayer1 = tf.nn.relu(tf.matmul(actLayer0, model.layers[1].weights[0]) + tf.ones([batch_size, 1]) * model.layers[1].bias)\n",
    "actLayer2 =            tf.matmul(actLayer1, model.layers[2].weights[0]) + tf.ones([batch_size, 1]) * model.layers[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=288, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[-0.714, -0.184,  0.177],\n",
       "       [-0.493, -0.146,  0.166],\n",
       "       [-0.621, -0.201,  0.158],\n",
       "       [-0.484, -0.204,  0.201],\n",
       "       [-0.577, -0.271,  0.243]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=292, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[-0.714, -0.184,  0.177],\n",
       "       [-0.493, -0.146,  0.166],\n",
       "       [-0.621, -0.201,  0.158],\n",
       "       [-0.484, -0.204,  0.201],\n",
       "       [-0.577, -0.271,  0.243]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actLayer2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=306, shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.   , 0.   , 0.   , 0.   , 0.32 , 0.   , 1.795, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.445, 0.   , 1.01 , 0.038, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.295, 0.017, 1.606, 0.059, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.616, 0.   , 0.9  , 0.122, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.746, 0.   , 1.114, 0.179, 0.   , 0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1](model.layers[0](features))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=310, shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.   , 0.   , 0.   , 0.   , 0.32 , 0.   , 1.795, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.445, 0.   , 1.01 , 0.038, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.295, 0.017, 1.606, 0.059, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.616, 0.   , 0.9  , 0.122, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.746, 0.   , 1.114, 0.179, 0.   , 0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actLayer1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax 적용 (로짓(logit)을 각 클래스에 대한 확률로 변환)\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdc1f8eaa8064d15893f1ba6426f20ff8e7149c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Prob. per Class: [0.195 0.331 0.475]\n",
      "Index: 1, Prob. per Class: [0.23  0.325 0.445]\n",
      "Index: 2, Prob. per Class: [0.213 0.324 0.464]\n",
      "Index: 3, Prob. per Class: [0.232 0.307 0.461]\n",
      "Index: 4, Prob. per Class: [0.216 0.293 0.491]\n"
     ]
    }
   ],
   "source": [
    "# Using Numpy\n",
    "for idx, logitRow in enumerate(predictions[:5]):\n",
    "    print('Index: {}, Prob. per Class: {}'.format(idx, np.exp(logitRow)/np.sum(np.exp(logitRow))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=339, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.195, 0.331, 0.475],\n",
       "       [0.23 , 0.325, 0.445],\n",
       "       [0.213, 0.324, 0.464],\n",
       "       [0.232, 0.307, 0.461],\n",
       "       [0.216, 0.293, 0.491]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using TensorFlow\n",
    "tf.nn.softmax(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  예측: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "레이블: [2 1 2 0 0 0 0 2 1 0 1 1 0 0 2 1 2 2 2 0 2 2 0 2 2 0 1 2 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"  예측: {}\".format(tf.argmax(predictions, axis=1)))\n",
    "print(\"레이블: {}\".format(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수 (Loss Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균 제곱 오차 (Mean Squared Error, MSE) : Regression (회귀) 문제에 주로 사용\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 엔트로피 오차 (Cross Entropy Error, CEE) : Classification (분류) 문제에 주로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/c6b895514e10a3ce88773852cba1cb1e248ed763)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0973685961216688\n"
     ]
    }
   ],
   "source": [
    "# Cross Entropy Error Using Numpy\n",
    "cee = 0\n",
    "for idx, prob in enumerate(tf.nn.softmax(model(features))):\n",
    "    y  = labels[idx]\n",
    "    y_ = prob[y]\n",
    "    cee = cee - np.log(y_)/batch_size\n",
    "print(cee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0973685\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.losses.SparseCategoricalCrossentropy: Computes the crossentropy loss between the labels and predictions.\n",
    "lossCEE = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "print(lossCEE(y_true=labels, y_pred=model(features)).numpy())\n",
    "def loss(model, x, y):\n",
    "  y_ = model(x)\n",
    "  return lossCEE(y_true=y, y_pred=y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옵티마이저 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cs231n.github.io/assets/nn3/opt1.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.GradientTape: Record operations for automatic differentiation.\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "# tf.keras.optimizers: Built-in optimizer classes.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "if optimizer.iterations.numpy() == 0:\n",
    "    mv1 = 0\n",
    "    mv2 = 0\n",
    "    t   = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단계: 0, 초기 손실: 1.0973684787750244\n",
      "단계: 1,     손실: 1.0545393228530884\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(4, 10), dtype=float32)\n",
      "[[ 0.006  0.     0.     0.001  0.006  0.    -0.031 -0.027  0.     0.027]\n",
      " [ 0.007  0.     0.     0.001  0.007  0.    -0.034 -0.013  0.     0.029]\n",
      " [-0.001  0.     0.     0.001 -0.005  0.     0.017 -0.016  0.    -0.016]\n",
      " [-0.001  0.     0.     0.    -0.003  0.     0.009 -0.005  0.    -0.009]]\n"
     ]
    }
   ],
   "source": [
    "loss_value, grads = grad(model, features, labels)\n",
    "\n",
    "print(\"단계: {}, 초기 손실: {}\".format(optimizer.iterations.numpy(), loss_value.numpy()))\n",
    "if optimizer.iterations == 0:\n",
    "    weights_pre  = tf.zeros([4,10])\n",
    "else:\n",
    "    weights_pre  = optimizer.weights[1].numpy()\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "print(\"단계: {},     손실: {}\".format(optimizer.iterations.numpy(), loss(model, features, labels).numpy()))\n",
    "weights_post = optimizer.weights[1].numpy()\n",
    "\n",
    "print(weights_pre)\n",
    "print(weights_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=922, shape=(4, 10), dtype=float32, numpy=\n",
       "array([[ 0.06 ,  0.   ,  0.   ,  0.012,  0.063,  0.   , -0.315, -0.265,  0.   ,  0.27 ],\n",
       "       [ 0.068,  0.   ,  0.   ,  0.007,  0.066,  0.   , -0.337, -0.133,  0.   ,  0.286],\n",
       "       [-0.015,  0.   ,  0.   ,  0.006, -0.051,  0.   ,  0.175, -0.158,  0.   , -0.163],\n",
       "       [-0.008,  0.   ,  0.   ,  0.002, -0.027,  0.   ,  0.093, -0.048,  0.   , -0.087]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$m_0 := 0 \\text{(Initialize initial 1st moment vector)}$$\n",
    "$$v_0 := 0 \\text{(Initialize initial 2nd moment vector)}$$\n",
    "$$t := 0 \\text{(Initialize timestep)}$$\n",
    "$$t := t + 1$$\n",
    "$$lr_t := \\text{learning\\_rate} * \\sqrt{1 - beta_2^t} / (1 - beta_1^t)$$\n",
    "$$m_t := beta_1 * m_{t-1} + (1 - beta_1) * g$$\n",
    "$$v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g$$\n",
    "$$variable := variable - lr_t * m_t / (\\sqrt{v_t} + \\epsilon)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.01  0.    0.   -0.01 -0.01  0.    0.01  0.01  0.   -0.01]\n",
      " [-0.01  0.    0.   -0.01 -0.01  0.    0.01  0.01  0.   -0.01]\n",
      " [ 0.01  0.    0.   -0.01  0.01  0.   -0.01  0.01  0.    0.01]\n",
      " [ 0.01  0.    0.   -0.01  0.01  0.   -0.01  0.01  0.    0.01]], shape=(4, 10), dtype=float32)\n",
      "[[ 0.006  0.     0.     0.001  0.006  0.    -0.031 -0.027  0.     0.027]\n",
      " [ 0.007  0.     0.     0.001  0.007  0.    -0.034 -0.013  0.     0.029]\n",
      " [-0.001  0.     0.     0.001 -0.005  0.     0.017 -0.016  0.    -0.016]\n",
      " [-0.001  0.     0.     0.    -0.003  0.     0.009 -0.005  0.    -0.009]]\n"
     ]
    }
   ],
   "source": [
    "if optimizer.iterations.numpy() != 0:\n",
    "    t   = t + 1\n",
    "    lr  = optimizer.learning_rate * np.sqrt(1-(optimizer.beta_2)**t) / (1-(optimizer.beta_1)**t)\n",
    "    mv1 = optimizer.beta_1.numpy() * mv1 + (1-optimizer.beta_1.numpy()) * grads[0].numpy()\n",
    "    mv2 = optimizer.beta_2.numpy() * mv2 + (1-optimizer.beta_2.numpy()) * grads[0].numpy() * grads[0].numpy()\n",
    "    \n",
    "weights_cal = weights_pre - lr * mv1 / (np.sqrt(mv2) + optimizer.epsilon)\n",
    "print(weights_cal)\n",
    "print(weights_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.638e-06, 0.000e+00, 0.000e+00, 1.329e-07, 4.026e-06, 0.000e+00, 9.920e-05, 7.047e-05, 0.000e+00, 7.267e-05],\n",
       "       [4.591e-06, 0.000e+00, 0.000e+00, 4.952e-08, 4.344e-06, 0.000e+00, 1.133e-04, 1.781e-05, 0.000e+00, 8.167e-05],\n",
       "       [2.162e-07, 0.000e+00, 0.000e+00, 3.564e-08, 2.608e-06, 0.000e+00, 3.045e-05, 2.499e-05, 0.000e+00, 2.663e-05],\n",
       "       [5.978e-08, 0.000e+00, 0.000e+00, 2.956e-09, 7.449e-07, 0.000e+00, 8.721e-06, 2.335e-06, 0.000e+00, 7.642e-06]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
